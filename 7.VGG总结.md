• VGG的网络结构有什么特点？卷积层和maxpool是按什么规律排布的？
	只使用3x3卷积 5个卷积块 + 3个全连接层 卷积块由3x3卷积(pad=1)组成， 每个卷积层保持输出大小=输入大小 
	卷积块内部没有pooling， 每个卷积块后面有max-pool max-pool的池化核为2，stride=2， max-pool后特征图长宽缩小一半 
	卷积块的通道数从64开始逐渐翻倍，最后到512
	每个卷积层后面都使用ReLU激活函数

• 如何理解VGG中的卷积块？多个3x3为什么可以代替一个大卷积核？代替后有哪些好处？
	VGG在整个网络中使用了非常小的3x3卷积，堆叠两个3x3卷积的感受野等于一个5x5卷积，堆叠三个3x3卷积的感受野等于一个7x7卷积。用多个3x3卷积去实现相同感受野的一个卷积核较大的卷积层
	①两个3x3中间有ReLU，增加了非线性操作，所以可以增加判别能力
	②使用多个3x3可以减少参数个数（可以缓解过拟合）
	
• VGG中是否使用了LRN，为什么？ 
	最初的A使用了，但对结果提升帮助不大，故弃用
	
• 什么是感受野？
	计算卷积时，输出特征图的像素点在输入特征图上映射的区域，即输出特征图一个点对应输入特征图上的区域
	
• 训练中使用动量，会对梯度产生什么影响？使用动量有什么好处？
	抵消梯度的偏差，缓解训练轨迹的抖动，从而加快训练速度
	
• weight decay对目标函数有什么影响？使用weight decay有什么好处？
	对权重进行L2正则化
	作用：约束权重weight的复杂程度，缓解过拟合
	
• VGG是如何初始化的？ 
	最初的做法：先训练最浅的网络A，训练更深的网络时， 前四个卷积层和后三个全连接层用模型A的参数初始化
	后来作者发现用Xavier方法可以对更深的网络也直接用 随机数初始化
	
• 如何理解Xavier初始化和Kaiming初始化的设计思路？
	为了防止出现梯度消失或梯度爆炸，合理的初始化应当保证让输入和输出的分布相同，由于初始化通常采用均匀分布或高斯分布（均值为0），需计算合理的初始化分布标准差
	Xavier初始化中仅考虑了sigmoid和tanh，Kaiming初始化考虑了ReLU
	
• VGG在训练和测试时都使用了多尺度图像扩增，有什么效果？
	使用256~512之间任意尺度对图像缩放，再随机取224大小的图像块 （相当于在图像平移扩增同时，加入图像缩放扩增）。对结果提升较为明显
	
• VGG还尝试了多个模型融合，有什么效果？
	训练多个模型，把softmax概率平均，可以进一步提升测试结果

• 为什么VGG最深为19层，不再继续增加层数？ 
	随着网络深度增加，精度不断提升到19层后精度趋于饱和